{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load And Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:59:01.562911Z",
     "start_time": "2020-05-19T09:59:01.544429Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "data = pickle.load(open(\"data/train_data.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:59:12.236609Z",
     "start_time": "2020-05-19T09:59:12.228663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Harini Komaravelli Test Analyst at Oracle, Hyderabad  Hyderabad, Telangana - Email me on Indeed: indeed.com/r/Harini- Komaravelli/2659eee82e435d1b  ➢ 6 Yrs. of IT Experience in Manual and Automation testing.  WORK EXPERIENCE  QA Analyst  Oracle  Test Analyst at Oracle, Hyderabad  Infosys Ltd -  Hyderabad, Telangana -  November 2011 to February 2016  Hyderabad from Nov 2011 to Feb17 2016 ➢ Worked in Tata Consultancy Services, Hyderabad from Feb 24 to Apr 11 2017 ➢ Currently working as a Test Analyst at Oracle, Hyderabad  QA Analyst with 6 years of IT experience  Oracle  EDUCATION  MCA  Osmania University  B.Sc. in Computer Science  Osmania University  SKILLS  Functional Testing, Blue Prism, Qtp  ADDITIONAL INFORMATION  Area of Expertise:  ➢ Familiar with Agile Methodologies. ➢ Having knowledge in Energy (Petroleum) & Health Care domains. ➢ Involved in preparation of Test Scenarios. ➢ Preparing Test Data for the test cases.  https://www.indeed.com/r/Harini-Komaravelli/2659eee82e435d1b?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Harini-Komaravelli/2659eee82e435d1b?isid=rex-download&ikw=download-top&co=IN   ➢ Experienced in development and execution of Test cases effectively. ➢ Experienced in Functional testing, GUI testing, Smoke testing, Regression testing and Integration Testing ➢ Experienced in doing Accessibility testing of an application ➢ Ability to understand user Requirements, Functional and Design specifications. ➢ Good knowledge of SDLC and STLC processes. ➢ Deciding the Severity and Priority of bugs. ➢ Experience in using Microsoft Test Manager & Oracle Test Manager as Test Management Tools. ➢ Having good experience in testing windows based & web based applications. ➢ Involved in Client Interactions for reviews, issues and for any clarifications. ➢ Web Services Testing ➢ Writing Test Scripts in QTP, Testcomplete. ➢ Creating Object Repositories and Function Libraries in QTP. ➢ Enhanced QTP scripts using VB Script. ➢ Strong experience in working with Blue Prism tool ➢ Worked on different Environments like Windows Application & Web Application  Technical Skills:  ❑ Test Automation Tools: Blue Prism, QTP 10.0, Testcomplete ❑ Test Management Tool: Microsoft Test Manager, Oracle Test Manager & JIRA ❑ Databases: Oracle 10g, SQL Server.  ❑ Operating Systems: Windows 7  Project 1: Title: Cadence Client: Baker Hughes  Technologies: Microsoft Visual Studio and Microsoft Team Foundation Server  Client Background: An oilfield services company delivering focused efforts on shale gas and other oilfield services. It provides services, tools and software for drilling and formation evaluation, well completion, production management, seismic data collection and interpretation.  Project Description: AUT (Application under test) is the next generation revolutionary, robust, easy to use scalable well site data acquisition processing and interpretation system for Client's Drilling Services to deliver services that meets cross divisional business requirements consistently.  Project 2:  Description: Paragon supports your entire care team with one tool that your clinicians need to help deliver the best patient care. Designed by physicians, nurses, pharmacists and mid level providers that have a first-hand understanding of clinical workflow needs, Paragon clinical applications allow your caregivers to focus on what matters most; spending time caring for patients. Since Paragon is fully-integrated across all applications and built around a single patient database, information    entered anywhere in the system is immediately available to the entire care team. Immediate access not only helps clinicians make better treatment decisions - it also helps promote patient safety. Paragon offers a broad suite of multidisciplinary clinical software solutions together with anytime, anywhere access to the complete patient record.  Responsibilities:  • Performed Smoke testing and Regression testing. • Involved in Generating and Executing Test Script using Quick Test Pro & Blue Prism • Usability and User Interface Testing. • Involved in Defect tracking and reporting the bugs using TFS • Participated in frequent walk-through meetings with Internal Quality Assurance groups and with development groups. • Participated in client calls and clarifying the doubts by having AT&T sessions • Involved in functional, regression and smoke testing to validate the application data changes done in windows application • Certifying the build status by running the scripts as part of smoke testing  Project 3:  Description: Food & Beverages R&A: Easily manage business across multiple locations while reducing IT cost and complexity. Cloud-based point-of-sale (POS) solutions enable centralized enterprise management with lower upfront costs and a smaller footprint.  Responsibilities:  • Performed Functional testing and Regression testing. • Involved in Generating and Executing Test Scripts using Blue Prism tool and Open script • Involved in preparing bots using Blue Prism tool. • Accessibility testing of the web application • Involved in Defect tracking and reporting the bugs using JIRA • WebServices testing by calling API's to export the data\",\n",
       " {'entities': [(2275, 2281, 'Companies worked at'),\n",
       "   (2235, 2241, 'Companies worked at'),\n",
       "   (1603, 1609, 'Companies worked at'),\n",
       "   (667, 703, 'Skills'),\n",
       "   (638, 658, 'College Name'),\n",
       "   (612, 637, 'Degree'),\n",
       "   (591, 611, 'College Name'),\n",
       "   (587, 590, 'Degree'),\n",
       "   (568, 574, 'Companies worked at'),\n",
       "   (526, 536, 'Designation'),\n",
       "   (515, 524, 'Location'),\n",
       "   (507, 513, 'Companies worked at'),\n",
       "   (491, 503, 'Designation'),\n",
       "   (429, 438, 'Location'),\n",
       "   (352, 361, 'Location'),\n",
       "   (296, 305, 'Location'),\n",
       "   (270, 279, 'Location'),\n",
       "   (262, 268, 'Companies worked at'),\n",
       "   (246, 258, 'Designation'),\n",
       "   (238, 244, 'Companies worked at'),\n",
       "   (226, 236, 'Designation'),\n",
       "   (177, 207, 'Designation'),\n",
       "   (150, 155, 'Years of Experience'),\n",
       "   (54, 63, 'Location'),\n",
       "   (43, 52, 'Location'),\n",
       "   (35, 41, 'Companies worked at'),\n",
       "   (19, 31, 'Designation'),\n",
       "   (0, 18, 'Name')]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train nlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T10:49:23.214047Z",
     "start_time": "2020-05-19T10:49:22.990621Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "\n",
    "def train_model(train_data):\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "        \n",
    "        \n",
    "        for _, anatotation in train_data:\n",
    "            for ent in anatotation['entities']:\n",
    "                ner.add_label(ent[2])\n",
    "        \n",
    "        \n",
    "    pipe_exceptions = [\"ner\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # reset and initialize the weights randomly – but only if we're\n",
    "        # training a new model\n",
    "        opt = nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Strt iter: \"+str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "            for texts, annotations  in train_data:\n",
    "                try:\n",
    "                    nlp.update(\n",
    "                    [texts],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop=0.3,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                    sgd=opt)\n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    pass\n",
    "                \n",
    "            print(\"Losses\", losses)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T10:51:13.278924Z",
     "start_time": "2020-05-19T10:49:24.240784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strt iter: 0\n",
      "Losses {'ner': 12910.276924661317}\n",
      "Strt iter: 1\n",
      "Losses {'ner': 9490.533529570856}\n",
      "Strt iter: 2\n",
      "Losses {'ner': 8509.357369359304}\n",
      "Strt iter: 3\n",
      "Losses {'ner': 8100.6438359973445}\n",
      "Strt iter: 4\n",
      "Losses {'ner': 7122.133079482255}\n",
      "Strt iter: 5\n",
      "Losses {'ner': 7863.632327497876}\n",
      "Strt iter: 6\n",
      "Losses {'ner': 6272.576605055368}\n",
      "Strt iter: 7\n",
      "Losses {'ner': 5664.183539927051}\n",
      "Strt iter: 8\n",
      "Losses {'ner': 5659.924423979124}\n",
      "Strt iter: 9\n",
      "Losses {'ner': 4956.2267034108345}\n"
     ]
    }
   ],
   "source": [
    "train_model(train_data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save NLP Model and Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T10:54:44.442696Z",
     "start_time": "2020-05-19T10:54:44.306214Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T10:54:46.957524Z",
     "start_time": "2020-05-19T10:54:46.907030Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.to_disk(\"model/ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T10:55:06.387377Z",
     "start_time": "2020-05-19T10:55:06.248940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta.json  ner\ttokenizer  vocab\r\n"
     ]
    }
   ],
   "source": [
    "!ls model/ner_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T10:55:31.226496Z",
     "start_time": "2020-05-19T10:55:30.816531Z"
    }
   },
   "outputs": [],
   "source": [
    "reloaded = spacy.load('model/ner_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T11:04:36.841058Z",
     "start_time": "2020-05-19T11:04:36.834002Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = \"Ramesh HP CES ASSOCIATE CONSULTANT  Bangalore, Karnataka - Email me on Indeed: indeed.com/r/Ramesh-HP/95fc615713630c4e  • 4 years of experience in engineering Technology software sales and strategic sourcing in B2B platform. • Proven track record of generating increased revenue by involving in professional sales strategies. • Responsible for software installation, network configuration, application integration with existing system and Technical support. • Effectively work with cross functional teams to deliver right solutions to client's requirements. • Complete involvement in client meetings with respect to requirement collection, suggesting solutions and financial negotiations. • Good experience in account management, having a track record of generating repeated business. • Responsible for report generation with respect qualified leads and expected commitments in closing deals. • Worked on a multiple market sector, responsibility to manage sector wise market analysis and drive business parallely.  Willing to relocate: Anywhere  WORK EXPERIENCE  CES ASSOCIATE CONSULTANT  SAP ARIBA -  November 2016 to October 2017  • Responsible for supplier management via Ariba Discovery Which is B2B consulting platform. • Strategic sourcing of supplier corresponding to the buyer's products & service based commodities globally. • Effectively analyse and conduct commodity research on project description from the buyer's postings. • Effective handling of multiple projects and converting potential leads into revenue for Ariba. • Having track record of maintaining 100% revenue target by monthly & quarterly.  SALES ENGINEER - CONCEPT TECHNOLOGY SOLUTION  -  January 2014 to November 2016  • Effective selling of CAD, CAM & Analysis Software's. Which has got multiple market sector. • Generating qualified leads by sourcing market, sector wise & implementing sales action plans. • Giving presentation about the company, products & service offers. • Identifying the client requirements, Plan for proposing a solution by integrating with internal technical team. • Provide value addition to the prospect by involving my superiors with client management team.  https://www.indeed.com/r/Ramesh-HP/95fc615713630c4e?isid=rex-download&ikw=download-top&co=IN   • Responsible to make negotiations and up closing the deals. • Provide technical support after sales and maintain healthy relationship with the prospect. • Responsible to achieve targets monthly, quarterly & annually.  EDUCATION  MCA in COMPUTER APPLICATION  Dayananda Sagar College of Engineering -  Bengaluru, Karnataka  BACHELOR OF SCIENCE in Electronics  Govt Science College -  Hassan, Karnataka  SKILLS  Lead genearation, Customer Handling, cold calling, Negotiation, upselling, IT sales, outbound calling, Technical Support, sales forcasting, Software sale, product demonstration, cross selling, Inside Sales, Technical sales, MS office, software integration, Network Management  ADDITIONAL INFORMATION  • Excellent Communication both verbal & written MS-Office • Sales Forecasting SAP Business Objective Tool • Strategic Prospecting Ariba Network Admin Tool • Product Knowledge Ariba B2B Cloud Platform • Social Networking • Negotiation • Customer Relationship Management • Technical Support\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T11:09:27.647731Z",
     "start_time": "2020-05-19T11:09:27.604113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                          - Ramesh HP\n",
      "Designation                   - CES ASSOCIATE CONSULTANT\n",
      "Location                      - Bangalore\n",
      "Email Address                 - indeed.com/r/Ramesh-HP/95fc615713630c4e\n",
      "Designation                   - CES ASSOCIATE CONSULTANT\n",
      "Companies worked at           - SAP ARIBA\n",
      "Degree                        - MCA in COMPUTER APPLICATION\n",
      "College Name                  - Dayananda Sagar College of Engineering\n",
      "Degree                        - BACHELOR OF SCIENCE in Electronics\n",
      "College Name                  - Govt Science College\n",
      "Skills                        - Lead genearation, Customer Handling, cold calling, Negotiation, upselling, IT sales, outbound calling, Technical Support, sales forcasting, Software sale, product demonstration, cross selling, Inside Sales, Technical sales, MS office, software integration, Network Management\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(cv)\n",
    "\n",
    "\n",
    "# [(ent.label_, ent.text) for ent in doc.ents]\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.label_ :{30}}- {ent.text}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
